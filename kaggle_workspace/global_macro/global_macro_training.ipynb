{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Global Macro Training (100M Steps)\n",
                "This notebook runs the trading agent training on 8 uncorrelated assets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Install Dependencies\n",
                "# protobuf==3.20.3 is critical to fix 'MessageFactory' error in Kaggle (TensorBoard mismatch)\n",
                "!pip install stable-baselines3 shimmy>=0.2.1 protobuf==3.20.3 pandas_ta"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Copy Code to Working Directory\n",
                "# Copying from 'global-macro-codes' dataset\n",
                "!cp /kaggle/input/global-macro-codes/*.py ./"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "08ffc63a",
            "metadata": {},
            "source": [
                "# 3. Overwrite Training Script with FIX (Column Capitalization & Date Indexing)\n",
                "This cell overwrites `train_global_kaggle.py`. \n",
                "**Fixes:**\n",
                "1.  **Capitalization**: Forces `close` -> `Close`.\n",
                "2.  **Date Indexing**: Moves 'Date' column to the Index so it doesn't crash the math."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3c2601d2",
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile train_global_kaggle.py\n",
                "import pandas as pd\n",
                "from stable_baselines3 import PPO\n",
                "from stable_baselines3.common.vec_env import SubprocVecEnv, VecNormalize\n",
                "from stable_baselines3.common.callbacks import EvalCallback\n",
                "import os\n",
                "\n",
                "from stock_env import StockTradingEnv\n",
                "from data_processor import add_technical_indicators, clean_data, load_data\n",
                "\n",
                "def make_env(rank, seed=0):\n",
                "    \"\"\"\n",
                "    Creates an environment for a specific asset based on the CPU rank.\n",
                "    \"\"\"\n",
                "    def _init():\n",
                "        # The \"Global Macro\" 8-Pack list\n",
                "        assets = [\n",
                "            'EUR_USD',      # 0\n",
                "            'GBP_USD',      # 1\n",
                "            'SPX500_USD',   # 2\n",
                "            'JP225_USD',    # 3\n",
                "            'XAU_USD',      # 4\n",
                "            'WTICO_USD',    # 5\n",
                "            'USB10Y_USD',   # 6\n",
                "            'CORN_USD'      # 7\n",
                "        ]\n",
                "        \n",
                "        # Select asset by rank\n",
                "        asset_name = assets[rank % len(assets)]\n",
                "        \n",
                "        # Load merged data (created by prepare_global_data.py)\n",
                "        # Kaggle Path (Dataset name: global-macro-data)\n",
                "        file_path = f\"/kaggle/input/global-macro-data/{asset_name}_merged.csv\"\n",
                "        \n",
                "        print(f\"[Rank {rank}] Loading {asset_name} from {file_path}...\")\n",
                "        \n",
                "        if not os.path.exists(file_path):\n",
                "             print(f\"ERROR: File not found {file_path}. Is data prep done?\")\n",
                "             raise FileNotFoundError(f\"{file_path}\")\n",
                "             \n",
                "        df = pd.read_csv(file_path)\n",
                "        \n",
                "        # FIX 1: Renaming columns to Title Case\n",
                "        df.columns = [c.capitalize() for c in df.columns]\n",
                "\n",
                "        # FIX 2: Set Date as Index (Critical logic from data_processor.load_data)\n",
                "        if 'Date' in df.columns:\n",
                "            df['Date'] = pd.to_datetime(df['Date'])\n",
                "            df.set_index('Date', inplace=True)\n",
                "        \n",
                "        # Preprocessing on the fly\n",
                "        df = add_technical_indicators(df)\n",
                "        df = clean_data(df)\n",
                "        \n",
                "        # Create environment with Random Start\n",
                "        env = StockTradingEnv(\n",
                "             df=df, \n",
                "             commission_pct=0.0001, \n",
                "             leverage=20.0, # Futures Leverage 1:20 (User Requested)\n",
                "             random_start=True,\n",
                "             stop_loss_pct=0.01, # 1% Risk\n",
                "             take_profit_pct=0.03 # 3% Reward (1:3 Ratio)\n",
                "        )\n",
                "        env.reset(seed=seed + rank)\n",
                "        return env\n",
                "    return _init\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    # Ensure output dirs\n",
                "    os.makedirs(\"checkpoints/global_macro\", exist_ok=True)\n",
                "    os.makedirs(\"logs/global_macro\", exist_ok=True)\n",
                "    \n",
                "    # Number of parallel environments = 8 assets\n",
                "    num_cpu = 8 \n",
                "    \n",
                "    print(f\"Starting Global Macro Training on {num_cpu} cores...\")\n",
                "    \n",
                "    # Create the parallel environments\n",
                "    # Normalizing Observations and Rewards (CRITICAL adaptation from past model)\n",
                "    # This helps the model handle different price scales (e.g. Gold 2000 vs EUR 1.05)\n",
                "    env = SubprocVecEnv([make_env(i) for i in range(num_cpu)])\n",
                "    env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=10.)\n",
                "\n",
                "    # Setup Eval Callback to save best model during the long run\n",
                "    eval_callback = EvalCallback(\n",
                "        env, \n",
                "        best_model_save_path='./checkpoints/global_macro/best_model',\n",
                "        log_path='./logs/global_macro',\n",
                "        eval_freq=100_000,\n",
                "        deterministic=True,\n",
                "        render=False\n",
                "    )\n",
                "\n",
                "    # Define the model (PPO)\n",
                "    # Refined Settings from past success:\n",
                "    # - net_arch=[128, 128]: Deeper network for complex patterns\n",
                "    # - batch_size=512: Better gradient estimation\n",
                "    # - ent_coef=0.01: High exploration for multi-asset\n",
                "    policy_kwargs = dict(net_arch=dict(pi=[128, 128], vf=[128, 128]))\n",
                "    \n",
                "    model = PPO(\n",
                "        \"MlpPolicy\", \n",
                "        env, \n",
                "        verbose=1, \n",
                "        ent_coef=0.01, \n",
                "        learning_rate=0.0003,\n",
                "        batch_size=512,\n",
                "        policy_kwargs=policy_kwargs,\n",
                "        tensorboard_log=\"./tensorboard_logs_global\"\n",
                "    )\n",
                "    \n",
                "    # Train\n",
                "    TOTAL_TIMESTEPS = 100_000_000\n",
                "    print(f\"Starting training for {TOTAL_TIMESTEPS} timesteps...\")\n",
                "    print(\"Strategy: Global Macro (8 Assets) | Random Start | Normalized | Recurrent-Ready\")\n",
                "    \n",
                "    try:\n",
                "        model.learn(total_timesteps=TOTAL_TIMESTEPS, callback=eval_callback)\n",
                "        model.save(\"checkpoints/global_macro/ppo_global_macro_final\")\n",
                "        env.save(\"checkpoints/global_macro/vec_normalize.pkl\") # Save normalization stats!\n",
                "        print(\"Training Complete. Model and Normalization stats saved.\")\n",
                "    except Exception as e:\n",
                "        print(f\"Training interrupted or failed: {e}\")\n",
                "        model.save(\"checkpoints/global_macro/ppo_global_macro_interrupted\")\n",
                "        env.save(\"checkpoints/global_macro/vec_normalize_interrupted.pkl\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Run Training\n",
                "!python train_global_kaggle.py"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
